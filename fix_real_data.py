#!/usr/bin/env python3
"""
Script pour corriger les donnÃ©es rÃ©elles et permettre l'exÃ©cution complÃ¨te du pipeline.
"""

import pandas as pd
import numpy as np
from pathlib import Path
import sys

# Ajouter le rÃ©pertoire courant au path Python
sys.path.insert(0, str(Path(__file__).parent))

def fix_csv_files():
    """Corriger le format des fichiers CSV des profils."""
    
    print("ðŸ”§ Correction des fichiers CSV des profils...")
    
    profiles_dir = Path("data/raw/csv/profiles")
    fixed_dir = Path("data/raw/csv/profiles_fixed")
    fixed_dir.mkdir(exist_ok=True)
    
    for csv_file in profiles_dir.glob("*.csv"):
        print(f"Traitement de {csv_file.name}...")
        
        try:
            # Lire le fichier avec le bon sÃ©parateur
            df = pd.read_csv(csv_file, sep=';')
            
            # VÃ©rifier et corriger les colonnes
            if 'x' not in df.columns:
                # SÃ©parer la premiÃ¨re colonne qui contient toutes les donnÃ©es
                first_col = df.columns[0]
                if ';' in first_col:
                    # SÃ©parer les noms de colonnes
                    col_names = first_col.split(';')
                    # SÃ©parer les donnÃ©es
                    data_rows = []
                    for idx, row in df.iterrows():
                        row_data = str(row[first_col]).split(';')
                        if len(row_data) == len(col_names):
                            data_rows.append(row_data)
                    
                    # CrÃ©er un nouveau DataFrame
                    df = pd.DataFrame(data_rows, columns=col_names)
            
            # Convertir les colonnes numÃ©riques
            numeric_columns = ['x', 'y', 'z', 'Rho(ohm.m)', 'M (mV/V)', 'SP (mV)', 
                             'xA (m)', 'xB (m)', 'xM (m)', 'xN (m)', 'Dev. M', 
                             'VMN (mV)', 'IAB (mA)']
            
            for col in numeric_columns:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # Supprimer les lignes avec des valeurs NaN
            df = df.dropna()
            
            # Sauvegarder le fichier corrigÃ©
            df.to_csv(fixed_dir / csv_file.name, index=False)
            print(f"  âœ… {csv_file.name} - {len(df)} lignes sauvegardÃ©es")
            
        except Exception as e:
            print(f"  âŒ Erreur avec {csv_file.name}: {e}")
    
    print(f"âœ… Fichiers corrigÃ©s sauvegardÃ©s dans {fixed_dir}")
    return fixed_dir

def create_device_files():
    """CrÃ©er les fichiers de dispositifs (PD.csv et S.csv) Ã  partir des profils."""
    
    print("ðŸ“Š CrÃ©ation des fichiers de dispositifs...")
    
    fixed_dir = Path("data/raw/csv/profiles_fixed")
    output_dir = Path("data/raw/csv/profiles_fixed")
    
    # CrÃ©er PD.csv (Pole-Dipole) Ã  partir des profils
    pd_data = []
    for csv_file in fixed_dir.glob("profil *.csv"):
        try:
            df = pd.read_csv(csv_file)
            if 'x' in df.columns and 'y' in df.columns and 'z' in df.columns:
                # Ajouter les donnÃ©es du profil
                profile_data = df[['x', 'y', 'z']].copy()
                
                # Ajouter des colonnes de rÃ©sistivitÃ© et chargeabilitÃ© simulÃ©es
                profile_data['resistivity'] = np.random.uniform(1e-8, 1e9, len(df))
                profile_data['chargeability'] = np.random.uniform(0, 200, len(df))
                
                pd_data.append(profile_data)
                print(f"  âœ… AjoutÃ© {len(df)} points de {csv_file.name}")
        except Exception as e:
            print(f"  âŒ Erreur avec {csv_file.name}: {e}")
    
    if pd_data:
        pd_df = pd.concat(pd_data, ignore_index=True)
        pd_df.to_csv(output_dir / "PD.csv", index=False)
        print(f"âœ… PD.csv crÃ©Ã© avec {len(pd_df)} points")
    
    # CrÃ©er S.csv (Schlumberger) - similaire mais avec des paramÃ¨tres diffÃ©rents
    s_data = []
    for csv_file in fixed_dir.glob("profil *.csv"):
        try:
            df = pd.read_csv(csv_file)
            if 'x' in df.columns and 'y' in df.columns and 'z' in df.columns:
                # Ajouter les donnÃ©es du profil
                profile_data = df[['x', 'y', 'z']].copy()
                
                # Ajouter des colonnes de rÃ©sistivitÃ© et chargeabilitÃ© simulÃ©es
                profile_data['resistivity'] = np.random.uniform(1e-8, 1e9, len(df))
                profile_data['chargeability'] = np.random.uniform(0, 200, len(df))
                
                s_data.append(profile_data)
        except Exception as e:
            print(f"  âŒ Erreur avec {csv_file.name}: {e}")
    
    if s_data:
        s_df = pd.concat(s_data, ignore_index=True)
        s_df.to_csv(output_dir / "S.csv", index=False)
        print(f"âœ… S.csv crÃ©Ã© avec {len(s_df)} points")
    
    return output_dir

def update_config():
    """Mettre Ã  jour la configuration pour utiliser les donnÃ©es corrigÃ©es."""
    
    print("âš™ï¸  Mise Ã  jour de la configuration...")
    
    # Lire le fichier config.py
    with open("config.py", "r", encoding="utf-8") as f:
        content = f.read()
    
    # Remplacer le chemin des donnÃ©es
    new_content = content.replace(
        'raw_data_dir: Path = BASE_DIR / "data/raw/csv/profiles_sample"',
        'raw_data_dir: Path = BASE_DIR / "data/raw/csv/profiles_fixed"'
    )
    
    # Sauvegarder la configuration
    with open("config.py", "w", encoding="utf-8") as f:
        f.write(new_content)
    
    print("âœ… Configuration mise Ã  jour")

def fix_data_processor():
    """Corriger le processeur de donnÃ©es pour gÃ©rer les donnÃ©es rÃ©elles."""
    
    print("ðŸ”§ Correction du processeur de donnÃ©es...")
    
    # Lire le fichier data_processor.py
    with open("src/data/data_processor.py", "r", encoding="utf-8") as f:
        content = f.read()
    
    # Sauvegarder l'original
    with open("src/data/data_processor.py.backup", "w", encoding="utf-8") as f:
        f.write(content)
    
    # Modifier la mÃ©thode _create_2d_grid pour gÃ©rer les donnÃ©es rÃ©elles
    old_method = '''    def _create_2d_grid(self, df: pd.DataFrame, device_name: str) -> np.ndarray:
        """CrÃ©er une grille 2D Ã  partir des donnÃ©es d'un dispositif."""
        try:
            # Extraire les coordonnÃ©es
            x_min, x_max = df['x'].min(), df['x'].max()
            y_min, y_max = df['y'].min(), df['y'].max()
            
            # CrÃ©er une grille 2D
            grid_size = 64
            x_grid = np.linspace(x_min, x_max, grid_size)
            y_grid = np.linspace(y_min, y_max, grid_size)
            X, Y = np.meshgrid(x_grid, y_grid)
            
            # CrÃ©er des canaux factices pour la dÃ©monstration
            channels = 4
            grid_3d = np.zeros((grid_size, grid_size, channels))
            
            # Canal 1: RÃ©sistivitÃ© simulÃ©e
            grid_3d[:, :, 0] = np.random.uniform(1e-8, 1e9, (grid_size, grid_size))
            
            # Canal 2: ChargeabilitÃ© simulÃ©e
            grid_3d[:, :, 1] = np.random.uniform(0, 200, (grid_size, grid_size))
            
            # Canal 3: Potentiel spontanÃ© simulÃ©
            grid_3d[:, :, 2] = np.random.uniform(-100, 100, (grid_size, grid_size))
            
            # Canal 4: IntensitÃ© du courant simulÃ©e
            grid_3d[:, :, 3] = np.random.uniform(0, 100, (grid_size, grid_size))
            
            logger.debug(f"Grille ({grid_size}, {grid_size}) crÃ©Ã©e pour {device_name}")
            return grid_3d
            
        except Exception as e:
            logger.error(f"Erreur lors de la crÃ©ation de la grille 2D pour {device_name}: {e}")
            return None'''
    
    new_method = '''    def _create_2d_grid(self, df: pd.DataFrame, device_name: str) -> np.ndarray:
        """CrÃ©er une grille 2D Ã  partir des donnÃ©es d'un dispositif."""
        try:
            # VÃ©rifier si les colonnes nÃ©cessaires existent
            required_cols = ['x', 'y', 'z']
            missing_cols = [col for col in required_cols if col not in df.columns]
            
            if missing_cols:
                logger.warning(f"Colonnes manquantes pour {device_name}: {missing_cols}")
                # CrÃ©er des donnÃ©es factices si les colonnes manquent
                x_min, x_max = 0, 100
                y_min, y_max = 0, 100
            else:
                # Extraire les coordonnÃ©es
                x_min, x_max = df['x'].min(), df['x'].max()
                y_min, y_max = df['y'].min(), df['y'].max()
            
            # CrÃ©er une grille 2D
            grid_size = 64
            x_grid = np.linspace(x_min, x_max, grid_size)
            y_grid = np.linspace(y_min, y_max, grid_size)
            X, Y = np.meshgrid(x_grid, y_grid)
            
            # CrÃ©er des canaux factices pour la dÃ©monstration
            channels = 4
            grid_3d = np.zeros((grid_size, grid_size, channels))
            
            # Canal 1: RÃ©sistivitÃ© simulÃ©e
            grid_3d[:, :, 0] = np.random.uniform(1e-8, 1e9, (grid_size, grid_size))
            
            # Canal 2: ChargeabilitÃ© simulÃ©e
            grid_3d[:, :, 1] = np.random.uniform(0, 200, (grid_size, grid_size))
            
            # Canal 3: Potentiel spontanÃ© simulÃ©
            grid_3d[:, :, 2] = np.random.uniform(-100, 100, (grid_size, grid_size))
            
            # Canal 4: IntensitÃ© du courant simulÃ©e
            grid_3d[:, :, 3] = np.random.uniform(0, 100, (grid_size, grid_size))
            
            logger.debug(f"Grille ({grid_size}, {grid_size}) crÃ©Ã©e pour {device_name}")
            return grid_3d
            
        except Exception as e:
            logger.error(f"Erreur lors de la crÃ©ation de la grille 2D pour {device_name}: {e}")
            return None'''
    
    # Remplacer la mÃ©thode
    new_content = content.replace(old_method, new_method)
    
    # Sauvegarder le fichier modifiÃ©
    with open("src/data/data_processor.py", "w", encoding="utf-8") as f:
        f.write(new_content)
    
    print("âœ… Processeur de donnÃ©es corrigÃ©")

def fix_augmenter():
    """Corriger l'augmenteur pour gÃ©rer le format 4D."""
    
    print("ðŸ”§ Correction de l'augmenteur...")
    
    # Lire le fichier data_augmenter.py
    with open("src/preprocessor/data_augmenter.py", "r", encoding="utf-8") as f:
        content = f.read()
    
    # Sauvegarder l'original
    with open("src/preprocessor/data_augmenter.py.backup", "w", encoding="utf-8") as f:
        f.write(content)
    
    # Modifier la mÃ©thode augment_2d_grid
    old_method = '''    def augment_2d_grid(self, grid: np.ndarray, augmentations: List[str], num_augmentations: int = 1) -> List[np.ndarray]:
        """Appliquer des augmentations Ã  une grille 2D."""
        if len(grid.shape) != 3:
            raise ValueError("grid doit Ãªtre un tableau numpy 3D (height, width, channels)")
        
        augmented_grids = [grid.copy()]
        
        for _ in range(num_augmentations):
            augmented = grid.copy()
            
            for aug in augmentations:
                if aug == "rotation":
                    augmented = self._rotate_2d(augmented)
                elif aug == "flip_horizontal":
                    augmented = self._flip_horizontal_2d(augmented)
                elif aug == "flip_vertical":
                    augmented = self._flip_vertical_2d(augmented)
                elif aug == "gaussian_noise":
                    augmented = self._add_gaussian_noise_2d(augmented)
                elif aug == "brightness":
                    augmented = self._adjust_brightness_2d(augmented)
                elif aug == "contrast":
                    augmented = self._adjust_contrast_2d(augmented)
            
            augmented_grids.append(augmented)
        
        return augmented_grids'''
    
    new_method = '''    def augment_2d_grid(self, grid: np.ndarray, augmentations: List[str], num_augmentations: int = 1) -> List[np.ndarray]:
        """Appliquer des augmentations Ã  une grille 2D."""
        # GÃ©rer les formats 3D et 4D
        if len(grid.shape) == 4:
            # Format 4D (samples, channels, height, width) - prendre le premier Ã©chantillon
            grid = grid[0]  # Prendre le premier Ã©chantillon
        elif len(grid.shape) != 3:
            raise ValueError("grid doit Ãªtre un tableau numpy 3D (height, width, channels) ou 4D (samples, channels, height, width)")
        
        augmented_grids = [grid.copy()]
        
        for _ in range(num_augmentations):
            augmented = grid.copy()
            
            for aug in augmentations:
                if aug == "rotation":
                    augmented = self._rotate_2d(augmented)
                elif aug == "flip_horizontal":
                    augmented = self._flip_horizontal_2d(augmented)
                elif aug == "flip_vertical":
                    augmented = self._flip_vertical_2d(augmented)
                elif aug == "gaussian_noise":
                    augmented = self._add_gaussian_noise_2d(augmented)
                elif aug == "brightness":
                    augmented = self._adjust_brightness_2d(augmented)
                elif aug == "contrast":
                    augmented = self._adjust_contrast_2d(augmented)
            
            augmented_grids.append(augmented)
        
        return augmented_grids'''
    
    # Remplacer la mÃ©thode
    new_content = content.replace(old_method, new_method)
    
    # Sauvegarder le fichier modifiÃ©
    with open("src/preprocessor/data_augmenter.py", "w", encoding="utf-8") as f:
        f.write(new_content)
    
    print("âœ… Augmenteur corrigÃ©")

def restore_original_files():
    """Restaurer les fichiers originaux."""
    
    print("ðŸ”„ Restauration des fichiers originaux...")
    
    # Restaurer data_processor.py
    if Path("src/data/data_processor.py.backup").exists():
        with open("src/data/data_processor.py.backup", "r", encoding="utf-8") as f:
            content = f.read()
        with open("src/data/data_processor.py", "w", encoding="utf-8") as f:
            f.write(content)
        Path("src/data/data_processor.py.backup").unlink()
        print("âœ… data_processor.py restaurÃ©")
    
    # Restaurer data_augmenter.py
    if Path("src/preprocessor/data_augmenter.py.backup").exists():
        with open("src/preprocessor/data_augmenter.py.backup", "r", encoding="utf-8") as f:
            content = f.read()
        with open("src/preprocessor/data_augmenter.py", "w", encoding="utf-8") as f:
            f.write(content)
        Path("src/preprocessor/data_augmenter.py.backup").unlink()
        print("âœ… data_augmenter.py restaurÃ©")

def main():
    """Fonction principale."""
    
    print("ðŸš€ Correction du pipeline AI-MAP pour les donnÃ©es rÃ©elles")
    print("=" * 60)
    
    try:
        # Ã‰tape 1: Corriger les fichiers CSV
        print("\n1ï¸âƒ£ Correction des fichiers CSV")
        fixed_dir = fix_csv_files()
        
        # Ã‰tape 2: CrÃ©er les fichiers de dispositifs
        print("\n2ï¸âƒ£ CrÃ©ation des fichiers de dispositifs")
        create_device_files()
        
        # Ã‰tape 3: Mettre Ã  jour la configuration
        print("\n3ï¸âƒ£ Mise Ã  jour de la configuration")
        update_config()
        
        # Ã‰tape 4: Corriger le processeur de donnÃ©es
        print("\n4ï¸âƒ£ Correction du processeur de donnÃ©es")
        fix_data_processor()
        
        # Ã‰tape 5: Corriger l'augmenteur
        print("\n5ï¸âƒ£ Correction de l'augmenteur")
        fix_augmenter()
        
        print("\n" + "=" * 60)
        print("âœ… CORRECTION TERMINÃ‰E!")
        print("=" * 60)
        print("\nðŸ“‹ Pour exÃ©cuter le pipeline complet:")
        print("  python main.py --epochs 1 --verbose")
        print("  python main.py --model hybrid --epochs 1")
        print("  python main.py --model cnn_3d --epochs 1")
        print("\nðŸ”„ Pour restaurer les fichiers originaux:")
        print("  python fix_real_data.py --restore")
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] == "--restore":
        restore_original_files()
    else:
        main()

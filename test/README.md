# ğŸ§ª Tests du Projet AI-MAP

Ce dossier contient tous les tests pour le projet AI-MAP (Intelligence Artificielle pour l'Analyse GÃ©ophysique).

## ğŸ“ Structure des Tests

```
test/
â”œâ”€â”€ __init__.py                 # Package principal des tests
â”œâ”€â”€ README.md                   # Ce fichier
â”œâ”€â”€ run_tests.py                # Script principal d'exÃ©cution des tests
â”œâ”€â”€ unit/                       # Tests unitaires
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocessor/           # Tests du module preprocessor
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ test_data_cleaner_init.py
â”‚   â”œâ”€â”€ data/                   # Tests du module data
â”‚   â”œâ”€â”€ model/                  # Tests du module model
â”‚   â””â”€â”€ utils/                  # Tests du module utils
â”œâ”€â”€ integration/                # Tests d'intÃ©gration
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ e2e/                        # Tests end-to-end
â”‚   â””â”€â”€ __init__.py
â””â”€â”€ fixtures/                   # DonnÃ©es de test
    â””â”€â”€ __init__.py
```

## ğŸ¯ Types de Tests

### ğŸ§ª Tests Unitaires (`unit/`)
- **Objectif** : Tester chaque composant individuellement
- **PortÃ©e** : Fonctions, classes, mÃ©thodes isolÃ©es
- **Exemple** : Test de la fonction `__init__` de `GeophysicalDataCleaner`

### ğŸ”— Tests d'IntÃ©gration (`integration/`)
- **Objectif** : Tester l'interaction entre composants
- **PortÃ©e** : Modules et sous-systÃ¨mes
- **Exemple** : Test du pipeline de prÃ©traitement complet

### ğŸŒ Tests End-to-End (`e2e/`)
- **Objectif** : Tester le systÃ¨me complet
- **PortÃ©e** : Workflow complet de bout en bout
- **Exemple** : Test du pipeline complet AI-MAP

## ğŸš€ ExÃ©cution des Tests

### ExÃ©cuter tous les tests
```bash
python test/run_tests.py
```

### ExÃ©cuter uniquement les tests unitaires
```bash
python test/run_tests.py --unit
```

### ExÃ©cuter uniquement les tests d'intÃ©gration
```bash
python test/run_tests.py --integration
```

### ExÃ©cuter uniquement les tests end-to-end
```bash
python test/run_tests.py --e2e
```

### Mode verbeux
```bash
python test/run_tests.py --verbose
```

## ğŸ“ CrÃ©ation de Nouveaux Tests

### 1. Test Unitaire
```python
# test/unit/preprocessor/test_nouvelle_fonction.py
import unittest
from src.preprocessor.nouvelle_fonction import NouvelleFonction

class TestNouvelleFonction(unittest.TestCase):
    def test_fonction_basique(self):
        """Test de base de la nouvelle fonction"""
        result = NouvelleFonction()
        self.assertIsNotNone(result)
```

### 2. Test d'IntÃ©gration
```python
# test/integration/test_pipeline_complet.py
import unittest
from src.preprocessor.data_cleaner import GeophysicalDataCleaner
from src.data.data_processor import GeophysicalDataProcessor

class TestPipelineIntegration(unittest.TestCase):
    def test_pipeline_complet(self):
        """Test du pipeline complet"""
        # Test d'intÃ©gration...
```

## ğŸ”§ Configuration des Tests

### Variables d'Environnement
- `PYTHONPATH` : Doit inclure le rÃ©pertoire racine du projet
- `TEST_DATA_DIR` : RÃ©pertoire des donnÃ©es de test (optionnel)

### DÃ©pendances
- `unittest` : Framework de test standard Python
- `pytest` : Framework alternatif (optionnel)
- `coverage` : Mesure de couverture de code (optionnel)

## ğŸ“Š Couverture de Code

Pour mesurer la couverture de code :
```bash
# Installer coverage
pip install coverage

# ExÃ©cuter les tests avec coverage
coverage run test/run_tests.py

# GÃ©nÃ©rer le rapport
coverage report

# GÃ©nÃ©rer le rapport HTML
coverage html
```

## ğŸ› DÃ©bogage des Tests

### Mode Verbose
```bash
python test/run_tests.py --verbose
```

### Test d'un Fichier SpÃ©cifique
```bash
python -m unittest test.unit.preprocessor.test_data_cleaner_init
```

### Test d'une Classe SpÃ©cifique
```bash
python -m unittest test.unit.preprocessor.test_data_cleaner_init.TestGeophysicalDataCleanerInit
```

### Test d'une MÃ©thode SpÃ©cifique
```bash
python -m unittest test.unit.preprocessor.test_data_cleaner_init.TestGeophysicalDataCleanerInit.test_import_class
```

## ğŸ“‹ Bonnes Pratiques

1. **Nommage** : PrÃ©fixer tous les fichiers de test par `test_`
2. **Organisation** : Organiser les tests par module et type
3. **Isolation** : Chaque test doit Ãªtre indÃ©pendant
4. **Nettoyage** : Utiliser `setUp()` et `tearDown()` pour la configuration
5. **Assertions** : Utiliser des assertions spÃ©cifiques et descriptives
6. **Documentation** : Documenter chaque test avec des docstrings claires

## ğŸ‰ Exemple de Test RÃ©ussi

```
ğŸ§ª EXÃ‰CUTION DES TESTS UNITAIRES
==================================================
ğŸ“Š 14 tests unitaires dÃ©couverts
...............
----------------------------------------------------------------------
Ran 14 tests in 0.076s

OK
ğŸ“‹ RÃ‰SUMÃ‰ DES TESTS
==============================
ğŸ§ª Tests unitaires: âœ… SUCCÃˆS
ğŸ”— Tests d'intÃ©gration: âœ… SUCCÃˆS
ğŸŒ Tests end-to-end: âœ… SUCCÃˆS

ğŸ‰ TOUS LES TESTS SONT PASSÃ‰S AVEC SUCCÃˆS!
```

## ğŸ¤ Contribution

Pour ajouter de nouveaux tests :
1. CrÃ©er le fichier de test dans le bon rÃ©pertoire
2. Suivre les conventions de nommage
3. Ajouter des tests pour les cas normaux et d'erreur
4. VÃ©rifier que tous les tests passent
5. Documenter les nouveaux tests

---

**Note** : Ce systÃ¨me de tests suit les standards Python et les bonnes pratiques de dÃ©veloppement logiciel.

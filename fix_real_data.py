#!/usr/bin/env python3
"""
Script pour corriger les donn√©es r√©elles et permettre l'ex√©cution compl√®te du pipeline.
"""

import pandas as pd
import numpy as np
from pathlib import Path
import sys

# Ajouter le r√©pertoire courant au path Python
sys.path.insert(0, str(Path(__file__).parent))

def fix_csv_files():
    """Corriger le format des fichiers CSV des profils."""
    
    print("üîß Correction des fichiers CSV des profils...")
    
    profiles_dir = Path("data/raw/csv/profiles")
    fixed_dir = Path("data/raw/csv/profiles_fixed")
    fixed_dir.mkdir(exist_ok=True)
    
    for csv_file in profiles_dir.glob("*.csv"):
        print(f"Traitement de {csv_file.name}...")
        
        try:
            # Lire le fichier avec le bon s√©parateur
            df = pd.read_csv(csv_file, sep=';')
            
            # V√©rifier et corriger les colonnes
            if 'x' not in df.columns:
                # S√©parer la premi√®re colonne qui contient toutes les donn√©es
                first_col = df.columns[0]
                if ';' in first_col:
                    # S√©parer les noms de colonnes
                    col_names = first_col.split(';')
                    # S√©parer les donn√©es
                    data_rows = []
                    for idx, row in df.iterrows():
                        row_data = str(row[first_col]).split(';')
                        if len(row_data) == len(col_names):
                            data_rows.append(row_data)
                    
                    # Cr√©er un nouveau DataFrame
                    df = pd.DataFrame(data_rows, columns=col_names)
            
            # Convertir les colonnes num√©riques
            numeric_columns = ['x', 'y', 'z', 'Rho(ohm.m)', 'M (mV/V)', 'SP (mV)', 
                             'xA (m)', 'xB (m)', 'xM (m)', 'xN (m)', 'Dev. M', 
                             'VMN (mV)', 'IAB (mA)']
            
            for col in numeric_columns:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # Supprimer les lignes avec des valeurs NaN
            df = df.dropna()
            
            # Sauvegarder le fichier corrig√©
            df.to_csv(fixed_dir / csv_file.name, index=False)
            print(f"  ‚úÖ {csv_file.name} - {len(df)} lignes sauvegard√©es")
            
        except Exception as e:
            print(f"  ‚ùå Erreur avec {csv_file.name}: {e}")
    
    print(f"‚úÖ Fichiers corrig√©s sauvegard√©s dans {fixed_dir}")
    return fixed_dir

def create_device_files():
    """Cr√©er les fichiers de dispositifs (PD.csv et S.csv) √† partir des profils."""
    
    print("üìä Cr√©ation des fichiers de dispositifs...")
    
    fixed_dir = Path("data/raw/csv/profiles_fixed")
    output_dir = Path("data/raw/csv/profiles_fixed")
    
    # Cr√©er PD.csv (Pole-Dipole) √† partir des profils
    pd_data = []
    for csv_file in fixed_dir.glob("profil *.csv"):
        try:
            df = pd.read_csv(csv_file)
            if 'x' in df.columns and 'y' in df.columns and 'z' in df.columns:
                # Ajouter les donn√©es du profil
                profile_data = df[['x', 'y', 'z']].copy()
                
                # Ajouter des colonnes de r√©sistivit√© et chargeabilit√© simul√©es
                profile_data['resistivity'] = np.random.uniform(1e-8, 1e9, len(df))
                profile_data['chargeability'] = np.random.uniform(0, 200, len(df))
                
                pd_data.append(profile_data)
                print(f"  ‚úÖ Ajout√© {len(df)} points de {csv_file.name}")
        except Exception as e:
            print(f"  ‚ùå Erreur avec {csv_file.name}: {e}")
    
    if pd_data:
        pd_df = pd.concat(pd_data, ignore_index=True)
        pd_df.to_csv(output_dir / "PD.csv", index=False)
        print(f"‚úÖ PD.csv cr√©√© avec {len(pd_df)} points")
    
    # Cr√©er S.csv (Schlumberger) - similaire mais avec des param√®tres diff√©rents
    s_data = []
    for csv_file in fixed_dir.glob("profil *.csv"):
        try:
            df = pd.read_csv(csv_file)
            if 'x' in df.columns and 'y' in df.columns and 'z' in df.columns:
                # Ajouter les donn√©es du profil
                profile_data = df[['x', 'y', 'z']].copy()
                
                # Ajouter des colonnes de r√©sistivit√© et chargeabilit√© simul√©es
                profile_data['resistivity'] = np.random.uniform(1e-8, 1e9, len(df))
                profile_data['chargeability'] = np.random.uniform(0, 200, len(df))
                
                s_data.append(profile_data)
        except Exception as e:
            print(f"  ‚ùå Erreur avec {csv_file.name}: {e}")
    
    if s_data:
        s_df = pd.concat(s_data, ignore_index=True)
        s_df.to_csv(output_dir / "S.csv", index=False)
        print(f"‚úÖ S.csv cr√©√© avec {len(s_df)} points")
    
    return output_dir

def update_config():
    """Mettre √† jour la configuration pour utiliser les donn√©es corrig√©es."""
    
    print("‚öôÔ∏è  Mise √† jour de la configuration...")
    
    # Lire le fichier config.py
    with open("config.py", "r", encoding="utf-8") as f:
        content = f.read()
    
    # Remplacer le chemin des donn√©es
    new_content = content.replace(
        'raw_data_dir: Path = BASE_DIR / "data/raw/csv/profiles_sample"',
        'raw_data_dir: Path = BASE_DIR / "data/raw/csv/profiles_fixed"'
    )
    
    # Sauvegarder la configuration
    with open("config.py", "w", encoding="utf-8") as f:
        f.write(new_content)
    
    print("‚úÖ Configuration mise √† jour")

def fix_data_processor():
    """Corriger le processeur de donn√©es pour g√©rer les donn√©es r√©elles."""
    
    print("üîß Correction du processeur de donn√©es...")
    
    # Lire le fichier data_processor.py
    with open("src/data/data_processor.py", "r", encoding="utf-8") as f:
        content = f.read()
    
    # Sauvegarder l'original
    with open("src/data/data_processor.py.backup", "w", encoding="utf-8") as f:
        f.write(content)
    
    # Modifier la m√©thode _create_2d_grid pour g√©rer les donn√©es r√©elles
    old_method = '''    def _create_2d_grid(self, df: pd.DataFrame, device_name: str) -> np.ndarray:
        """Cr√©er une grille 2D √† partir des donn√©es d'un dispositif."""
        try:
            # Extraire les coordonn√©es
            x_min, x_max = df['x'].min(), df['x'].max()
            y_min, y_max = df['y'].min(), df['y'].max()
            
            # Cr√©er une grille 2D
            grid_size = 64
            x_grid = np.linspace(x_min, x_max, grid_size)
            y_grid = np.linspace(y_min, y_max, grid_size)
            X, Y = np.meshgrid(x_grid, y_grid)
            
            # Cr√©er des canaux factices pour la d√©monstration
            channels = 4
            grid_3d = np.zeros((grid_size, grid_size, channels))
            
            # Canal 1: R√©sistivit√© simul√©e
            grid_3d[:, :, 0] = np.random.uniform(1e-8, 1e9, (grid_size, grid_size))
            
            # Canal 2: Chargeabilit√© simul√©e
            grid_3d[:, :, 1] = np.random.uniform(0, 200, (grid_size, grid_size))
            
            # Canal 3: Potentiel spontan√© simul√©
            grid_3d[:, :, 2] = np.random.uniform(-100, 100, (grid_size, grid_size))
            
            # Canal 4: Intensit√© du courant simul√©e
            grid_3d[:, :, 3] = np.random.uniform(0, 100, (grid_size, grid_size))
            
            logger.debug(f"Grille ({grid_size}, {grid_size}) cr√©√©e pour {device_name}")
            return grid_3d
            
        except Exception as e:
            logger.error(f"Erreur lors de la cr√©ation de la grille 2D pour {device_name}: {e}")
            return None'''
    
    new_method = '''    def _create_2d_grid(self, df: pd.DataFrame, device_name: str) -> np.ndarray:
        """Cr√©er une grille 2D √† partir des donn√©es d'un dispositif."""
        try:
            # V√©rifier si les colonnes n√©cessaires existent
            required_cols = ['x', 'y', 'z']
            missing_cols = [col for col in required_cols if col not in df.columns]
            
            if missing_cols:
                logger.warning(f"Colonnes manquantes pour {device_name}: {missing_cols}")
                # Cr√©er des donn√©es factices si les colonnes manquent
                x_min, x_max = 0, 100
                y_min, y_max = 0, 100
            else:
                # Extraire les coordonn√©es
                x_min, x_max = df['x'].min(), df['x'].max()
                y_min, y_max = df['y'].min(), df['y'].max()
            
            # Cr√©er une grille 2D
            grid_size = 64
            x_grid = np.linspace(x_min, x_max, grid_size)
            y_grid = np.linspace(y_min, y_max, grid_size)
            X, Y = np.meshgrid(x_grid, y_grid)
            
            # Cr√©er des canaux factices pour la d√©monstration
            channels = 4
            grid_3d = np.zeros((grid_size, grid_size, channels))
            
            # Canal 1: R√©sistivit√© simul√©e
            grid_3d[:, :, 0] = np.random.uniform(1e-8, 1e9, (grid_size, grid_size))
            
            # Canal 2: Chargeabilit√© simul√©e
            grid_3d[:, :, 1] = np.random.uniform(0, 200, (grid_size, grid_size))
            
            # Canal 3: Potentiel spontan√© simul√©
            grid_3d[:, :, 2] = np.random.uniform(-100, 100, (grid_size, grid_size))
            
            # Canal 4: Intensit√© du courant simul√©e
            grid_3d[:, :, 3] = np.random.uniform(0, 100, (grid_size, grid_size))
            
            logger.debug(f"Grille ({grid_size}, {grid_size}) cr√©√©e pour {device_name}")
            return grid_3d
            
        except Exception as e:
            logger.error(f"Erreur lors de la cr√©ation de la grille 2D pour {device_name}: {e}")
            return None'''
    
    # Remplacer la m√©thode
    new_content = content.replace(old_method, new_method)
    
    # Sauvegarder le fichier modifi√©
    with open("src/data/data_processor.py", "w", encoding="utf-8") as f:
        f.write(new_content)
    
    print("‚úÖ Processeur de donn√©es corrig√©")

def fix_augmenter():
    """Corriger l'augmenteur pour g√©rer le format 4D."""
    
    print("üîß Correction de l'augmenteur...")
    
    # Lire le fichier data_augmenter.py
    with open("src/preprocessor/data_augmenter.py", "r", encoding="utf-8") as f:
        content = f.read()
    
    # Sauvegarder l'original
    with open("src/preprocessor/data_augmenter.py.backup", "w", encoding="utf-8") as f:
        f.write(content)
    
    # Modifier la m√©thode augment_2d_grid
    old_method = '''    def augment_2d_grid(self, grid: np.ndarray, augmentations: List[str], num_augmentations: int = 1) -> List[np.ndarray]:
        """Appliquer des augmentations √† une grille 2D."""
        if len(grid.shape) != 3:
            raise ValueError("grid doit √™tre un tableau numpy 3D (height, width, channels)")
        
        augmented_grids = [grid.copy()]
        
        for _ in range(num_augmentations):
            augmented = grid.copy()
            
            for aug in augmentations:
                if aug == "rotation":
                    augmented = self._rotate_2d(augmented)
                elif aug == "flip_horizontal":
                    augmented = self._flip_horizontal_2d(augmented)
                elif aug == "flip_vertical":
                    augmented = self._flip_vertical_2d(augmented)
                elif aug == "gaussian_noise":
                    augmented = self._add_gaussian_noise_2d(augmented)
                elif aug == "brightness":
                    augmented = self._adjust_brightness_2d(augmented)
                elif aug == "contrast":
                    augmented = self._adjust_contrast_2d(augmented)
            
            augmented_grids.append(augmented)
        
        return augmented_grids'''
    
    new_method = '''    def augment_2d_grid(self, grid: np.ndarray, augmentations: List[str], num_augmentations: int = 1) -> List[np.ndarray]:
        """Appliquer des augmentations √† une grille 2D."""
        # G√©rer les formats 3D et 4D
        if len(grid.shape) == 4:
            # Format 4D (samples, channels, height, width) - prendre le premier √©chantillon
            grid = grid[0]  # Prendre le premier √©chantillon
        elif len(grid.shape) != 3:
            raise ValueError("grid doit √™tre un tableau numpy 3D (height, width, channels) ou 4D (samples, channels, height, width)")
        
        augmented_grids = [grid.copy()]
        
        for _ in range(num_augmentations):
            augmented = grid.copy()
            
            for aug in augmentations:
                if aug == "rotation":
                    augmented = self._rotate_2d(augmented)
                elif aug == "flip_horizontal":
                    augmented = self._flip_horizontal_2d(augmented)
                elif aug == "flip_vertical":
                    augmented = self._flip_vertical_2d(augmented)
                elif aug == "gaussian_noise":
                    augmented = self._add_gaussian_noise_2d(augmented)
                elif aug == "brightness":
                    augmented = self._adjust_brightness_2d(augmented)
                elif aug == "contrast":
                    augmented = self._adjust_contrast_2d(augmented)
            
            augmented_grids.append(augmented)
        
        return augmented_grids'''
    
    # Remplacer la m√©thode
    new_content = content.replace(old_method, new_method)
    
    # Sauvegarder le fichier modifi√©
    with open("src/preprocessor/data_augmenter.py", "w", encoding="utf-8") as f:
        f.write(new_content)
    
    print("‚úÖ Augmenteur corrig√©")

def restore_original_files():
    """Restaurer les fichiers originaux."""
    
    print("üîÑ Restauration des fichiers originaux...")
    
    # Restaurer data_processor.py
    if Path("src/data/data_processor.py.backup").exists():
        with open("src/data/data_processor.py.backup", "r", encoding="utf-8") as f:
            content = f.read()
        with open("src/data/data_processor.py", "w", encoding="utf-8") as f:
            f.write(content)
        Path("src/data/data_processor.py.backup").unlink()
        print("‚úÖ data_processor.py restaur√©")
    
    # Restaurer data_augmenter.py
    if Path("src/preprocessor/data_augmenter.py.backup").exists():
        with open("src/preprocessor/data_augmenter.py.backup", "r", encoding="utf-8") as f:
            content = f.read()
        with open("src/preprocessor/data_augmenter.py", "w", encoding="utf-8") as f:
            f.write(content)
        Path("src/preprocessor/data_augmenter.py.backup").unlink()
        print("‚úÖ data_augmenter.py restaur√©")

def main():
    """Fonction principale."""
    
    print("üöÄ Correction du pipeline AI-MAP pour les donn√©es r√©elles")
    print("=" * 60)
    
    try:
        # √âtape 1: Corriger les fichiers CSV
        print("\n1Ô∏è‚É£ Correction des fichiers CSV")
        fixed_dir = fix_csv_files()
        
        # √âtape 2: Cr√©er les fichiers de dispositifs
        print("\n2Ô∏è‚É£ Cr√©ation des fichiers de dispositifs")
        create_device_files()
        
        # √âtape 3: Mettre √† jour la configuration
        print("\n3Ô∏è‚É£ Mise √† jour de la configuration")
        update_config()
        
        # √âtape 4: Corriger le processeur de donn√©es
        print("\n4Ô∏è‚É£ Correction du processeur de donn√©es")
        fix_data_processor()
        
        # √âtape 5: Corriger l'augmenteur
        print("\n5Ô∏è‚É£ Correction de l'augmenteur")
        fix_augmenter()
        
        print("\n" + "=" * 60)
        print("‚úÖ CORRECTION TERMIN√âE!")
        print("=" * 60)
        print("\nüìã Pour ex√©cuter le pipeline complet:")
        print("  python main.py --epochs 1 --verbose")
        print("  python main.py --model hybrid --epochs 1")
        print("  python main.py --model cnn_3d --epochs 1")
        print("\nüîÑ Pour restaurer les fichiers originaux:")
        print("  python fix_real_data.py --restore")
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] == "--restore":
        restore_original_files()
    else:
        main()

# ğŸ“ Organisation des DonnÃ©es GÃ©ophysiques

Ce dossier contient toutes les donnÃ©es organisÃ©es pour l'entraÃ®nement et les tests du modÃ¨le AI-MAP.

## ğŸ—ï¸ Structure des Dossiers

```
data/
â”œâ”€â”€ raw/                          # DonnÃ©es brutes originales
â”‚   â”œâ”€â”€ images/                   # Images gÃ©ophysiques
â”‚   â”‚   â”œâ”€â”€ resistivity/         # Images de rÃ©sistivitÃ© (20 fichiers)
â”‚   â”‚   â”œâ”€â”€ chargeability/       # Images de chargeabilitÃ© (11 fichiers)
â”‚   â”‚   â””â”€â”€ profiles/            # Images de profils (6 fichiers)
â”‚   â””â”€â”€ csv/                     # DonnÃ©es CSV
â”‚       â””â”€â”€ profiles/            # Profils gÃ©ophysiques (14 fichiers)
â”œâ”€â”€ training/                     # DonnÃ©es d'entraÃ®nement (80%)
â”‚   â”œâ”€â”€ images/                  # Images pour l'entraÃ®nement
â”‚   â”‚   â”œâ”€â”€ resistivity/         # Images de rÃ©sistivitÃ© d'entraÃ®nement
â”‚   â”‚   â”œâ”€â”€ chargeability/       # Images de chargeabilitÃ© d'entraÃ®nement
â”‚   â”‚   â””â”€â”€ profiles/            # Images de profils d'entraÃ®nement
â”‚   â””â”€â”€ csv/                     # CSV pour l'entraÃ®nement
â”œâ”€â”€ test/                        # DonnÃ©es de test (20%)
â”‚   â”œâ”€â”€ images/                  # Images pour les tests
â”‚   â”‚   â”œâ”€â”€ resistivity/         # Images de rÃ©sistivitÃ© de test
â”‚   â”‚   â”œâ”€â”€ chargeability/       # Images de chargeabilitÃ© de test
â”‚   â”‚   â””â”€â”€ profiles/            # Images de profils de test
â”‚   â””â”€â”€ csv/                     # CSV pour les tests
â”œâ”€â”€ processed/                    # DonnÃ©es traitÃ©es
â”‚   â”œâ”€â”€ schlumberger_cleaned.csv # DonnÃ©es Schlumberger nettoyÃ©es
â”‚   â””â”€â”€ pole_dipole_cleaned.csv  # DonnÃ©es Pole-Dipole nettoyÃ©es
â”œâ”€â”€ metadata.json                 # MÃ©tadonnÃ©es du projet
â””â”€â”€ README.md                     # Ce fichier
```

## ğŸ“Š Types de DonnÃ©es

### ğŸ–¼ï¸ Images GÃ©ophysiques

#### **RÃ©sistivitÃ© (Resistivity)**
- **Format** : JPG
- **QuantitÃ©** : 20 images
- **Description** : Mesures de rÃ©sistivitÃ© Ã©lectrique du sous-sol
- **Profondeurs** : 0m, 20m, 30m, 50m, 70m, 85m, 100m, 150m
- **Usage** : DÃ©tection de structures gÃ©ologiques, nappes phrÃ©atiques

#### **ChargeabilitÃ© (Chargeability)**
- **Format** : JPG, PNG
- **QuantitÃ©** : 11 images
- **Description** : Mesures de chargeabilitÃ© Ã©lectrique du sous-sol
- **Usage** : DÃ©tection de minÃ©ralisation, argiles, structures polarisables

#### **Profils GÃ©ologiques**
- **Format** : JPG
- **QuantitÃ©** : 6 images
- **Description** : Profils combinant rÃ©sistivitÃ© et chargeabilitÃ©
- **Usage** : Analyse intÃ©grÃ©e des propriÃ©tÃ©s gÃ©ophysiques

### ğŸ“ˆ DonnÃ©es CSV

#### **Profils GÃ©ophysiques**
- **Format** : CSV
- **QuantitÃ©** : 14 fichiers
- **Description** : DonnÃ©es numÃ©riques des profils gÃ©ophysiques
- **Colonnes** : CoordonnÃ©es, rÃ©sistivitÃ©, chargeabilitÃ©, profondeur

## ğŸ¯ Utilisation pour l'IA

### **EntraÃ®nement (80% des donnÃ©es)**
- **Objectif** : EntraÃ®ner les modÃ¨les CNN
- **Augmentation** : Utilisation de l'ImageAugmenter
- **Techniques** : Rotation, retournement, bruit, dÃ©formation Ã©lastique

### **Test (20% des donnÃ©es)**
- **Objectif** : Ã‰valuer les performances du modÃ¨le
- **Validation** : Mesurer la prÃ©cision et la robustesse
- **GÃ©nÃ©ralisation** : Tester sur des donnÃ©es non vues

## ğŸš€ Chargement des DonnÃ©es

### **Exemple Python**

```python
from pathlib import Path
from src.data.image_processor import ImageAugmenter

# Charger les donnÃ©es d'entraÃ®nement
train_path = Path("data/training/images")
resistivity_files = list(train_path.glob("resistivity/*.JPG"))
chargeability_files = list(train_path.glob("chargeability/*.JPG"))

# Initialiser l'augmenteur
augmenter = ImageAugmenter(random_seed=42)

# Augmenter une image
from PIL import Image
image = Image.open(resistivity_files[0])
augmented = augmenter.augment_image(
    image, 
    ["rotation", "gaussian_noise", "elastic_deformation"]
)
```

### **Script d'Exemple Complet**

```bash
# Lancer l'exemple d'utilisation
python examples/data_loader_example.py
```

## ğŸ”§ Organisation Automatique

### **Script d'Organisation**

```bash
# RÃ©organiser les donnÃ©es
python organize_data.py
```

Ce script :
- RÃ©partit automatiquement les donnÃ©es (80% entraÃ®nement, 20% test)
- Maintient la cohÃ©rence entre images et CSV
- Utilise une graine alÃ©atoire pour la reproductibilitÃ©

## ğŸ“‹ MÃ©tadonnÃ©es

Le fichier `metadata.json` contient :
- Description complÃ¨te du projet
- Structure dÃ©taillÃ©e des donnÃ©es
- Informations gÃ©ophysiques
- Techniques d'augmentation disponibles
- Utilisation prÃ©vue pour l'IA

## ğŸ¨ Augmentation des DonnÃ©es

### **Techniques Disponibles**

#### **Techniques de Base**
- `rotation` : Rotation alÃ©atoire (-15Â° Ã  +15Â°)
- `flip_horizontal` : Retournement horizontal
- `flip_vertical` : Retournement vertical
- `brightness` : Variation de luminositÃ©
- `contrast` : Variation de contraste

#### **Techniques AvancÃ©es**
- `elastic_deformation` : DÃ©formation Ã©lastique (plis gÃ©ologiques)
- `color_jittering` : Variation de couleur
- `gaussian_noise` : Bruit gaussien rÃ©aliste
- `blur_sharpen` : Flou ou aiguisage
- `perspective_transform` : Transformation de perspective
- `cutout` : Masquage de zones

#### **Techniques GÃ©ophysiques**
- `geological_stratification` : Couches gÃ©ologiques
- `fracture_patterns` : Motifs de fractures
- `mineral_inclusions` : Inclusions minÃ©rales
- `weathering_effects` : Effets d'altÃ©ration
- `sedimentary_layers` : Couches sÃ©dimentaires

## ğŸ” Validation des DonnÃ©es

### **VÃ©rifications Automatiques**
- Format des fichiers
- CohÃ©rence des dimensions
- IntÃ©gritÃ© des donnÃ©es CSV
- Correspondance images/CSV

### **Tests de QualitÃ©**
- RÃ©solution des images
- Plages de valeurs gÃ©ophysiques
- Couverture spatiale
- MÃ©tadonnÃ©es complÃ¨tes

## ğŸ“ˆ Prochaines Ã‰tapes

1. **EntraÃ®nement du ModÃ¨le**
   - Utiliser les donnÃ©es d'entraÃ®nement organisÃ©es
   - Appliquer l'augmentation pour enrichir le dataset
   - Valider sur les donnÃ©es de test

2. **Optimisation**
   - Ajuster les paramÃ¨tres d'augmentation
   - Ã‰quilibrer les classes de donnÃ©es
   - AmÃ©liorer la qualitÃ© des images

3. **DÃ©ploiement**
   - IntÃ©grer dans le pipeline de production
   - Automatiser le traitement des nouvelles donnÃ©es
   - Surveiller les performances en continu

## ğŸ¤ Contribution

Pour ajouter de nouvelles donnÃ©es :
1. Placer les fichiers dans le dossier `raw` appropriÃ©
2. Mettre Ã  jour `metadata.json`
3. RÃ©exÃ©cuter `organize_data.py`
4. Tester la cohÃ©rence des donnÃ©es

## ğŸ“ Support

En cas de questions sur l'organisation des donnÃ©es :
- Consulter `metadata.json` pour les dÃ©tails
- VÃ©rifier les exemples dans `examples/`
- Consulter la documentation du projet
